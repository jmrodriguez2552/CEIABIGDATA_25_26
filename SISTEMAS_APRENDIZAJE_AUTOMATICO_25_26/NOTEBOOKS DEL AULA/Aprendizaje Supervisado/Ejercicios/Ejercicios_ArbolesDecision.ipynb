{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica: Árboles de Decisión (Clasificación)\n",
    "\n",
    "**Profesor:** Carlos Tessier Fernández\n",
    "**Módulo:** Sistemas de aprendizaje automático (SAA) \n",
    "**Objetivo:** Aplicar un Árbol de Decisión para clasificar especies de pingüinos [RA3, cite: 785].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto\n",
    "\n",
    "Vamos a utilizar el dataset `Pinguinos.csv`. El objetivo es entrenar un modelo que pueda predecir la **especie** (`species`) de un pingüino basándose en sus características físicas (longitud del pico, longitud de la aleta, masa corporal, etc.) y su ubicación (`island`, `sex`).\n",
    "\n",
    "**Target (Objetivo):** `species` (Adelie, Chinstrap, Gentoo)\n",
    "**Features (Características):** Todas las demás columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Importar Librerías y Cargar Datos\n",
    "\n",
    "Importa `pandas`, `train_test_split`, `DecisionTreeClassifier`, `accuracy_score`, `confusion_matrix`, `LabelEncoder` y `plot_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 1.1: Importa todas las librerías necesarias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# ... (importa el resto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 1.2: Carga el dataset 'Pinguinos.csv' en un DataFrame llamado 'df'\n",
    "df = pd.read_csv('Pinguinos.csv')\n",
    "\n",
    "# HUECO 1.3: Explora los datos (usa .info() y .head())\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Preprocesamiento de Datos (Limpieza y Codificación)\n",
    "\n",
    "Como hemos visto con `.info()`, hay valores nulos (NaN) y columnas de tipo `object` (categóricas) que `scikit-learn` no puede procesar directamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea 2.1: Manejar valores nulos**\n",
    "\n",
    "Por simplicidad, vamos a eliminar cualquier fila que contenga al menos un valor nulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 2.1: Elimina las filas con valores nulos (NaN) del DataFrame 'df'\n",
    "# Pista: usa .dropna()\n",
    "\n",
    "# Comprueba con df.info() que ya no hay nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea 2.2: Codificar variables categóricas**\n",
    "\n",
    "Necesitamos convertir las columnas `species` (nuestro target), `island` y `sex` (features) a números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso de ```LabelEncoder```:   \n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Datos de Ejemplo ---\n",
    "# Imagina que tenemos datos de una variable categorica (texto).\n",
    "# 'LabelEncoder' se usa tipicamente para la variable OBJETIVO (la 'y').\n",
    "# Para las variables FEATURES (la 'X'), es mas comun usar OneHotEncoder,\n",
    "# pero LabelEncoder tambien se usa a veces si la cardinalidad es baja.\n",
    "\n",
    "labels = ['Adelie', 'Gentoo', 'Chinstrap', 'Adelie', 'Gentoo']\n",
    "print(f\"Datos Originales: {labels}\")\n",
    "print(\"---\")\n",
    "\n",
    "# 1. Inicializar el codificador\n",
    "# Creamos una instancia de la clase\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 2. Ajustar y Transformar (fit_transform)\n",
    "# El metodo .fit_transform() hace dos cosas:\n",
    "# 1. .fit(): Aprende el mapeo (las clases unicas). Asigna un numero\n",
    "#            a cada clase por orden alfabetico.\n",
    "# 2. .transform(): Aplica ese mapeo a los datos.\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "\n",
    "print(f\"Datos Codificados: {encoded_labels}\")\n",
    "print(\"---\")\n",
    "\n",
    "# 3. Ver las clases aprendidas\n",
    "# El atributo .classes_ nos muestra el mapeo.\n",
    "# El indice del array corresponde al numero asignado.\n",
    "# (0 -> 'Adelie', 1 -> 'Chinstrap', 2 -> 'Gentoo')\n",
    "print(f\"Clases aprendidas (mapeo): {le.classes_}\")\n",
    "print(\"---\")\n",
    "\n",
    "\n",
    "# 4. Transformar datos nuevos\n",
    "# Si aparece un dato que el encoder ya conoce (ej. 'Gentoo')\n",
    "nuevo_dato = ['Gentoo']\n",
    "print(f\"Dato nuevo: {nuevo_dato}\")\n",
    "print(f\"Dato nuevo codificado: {le.transform(nuevo_dato)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# 5. Invertir la transformacion (inverse_transform)\n",
    "# Esto es muy util para interpretar las predicciones del modelo.\n",
    "# Si el modelo predice [2, 0, 1], ¿que especies son?\n",
    "predicciones_numericas = np.array([2, 0, 1, 0])\n",
    "predicciones_originales = le.inverse_transform(predicciones_numericas)\n",
    "\n",
    "print(f\"Predicciones (numeros): {predicciones_numericas}\")\n",
    "print(f\"Predicciones (texto):   {predicciones_originales}\")\n",
    "```   \n",
    "OBTENEMOS:    \n",
    "```\n",
    "Datos Originales: ['Adelie', 'Gentoo', 'Chinstrap', 'Adelie', 'Gentoo']\n",
    "---\n",
    "Datos Codificados: [0 2 1 0 2]\n",
    "---\n",
    "Clases aprendidas (mapeo): ['Adelie' 'Chinstrap' 'Gentoo']\n",
    "---\n",
    "Dato nuevo: ['Gentoo']\n",
    "Dato nuevo codificado: [2]\n",
    "---\n",
    "Predicciones (numeros): [2 0 1 0]\n",
    "Predicciones (texto):   ['Gentoo' 'Adelie' 'Chinstrap' 'Adelie']\n",
    "```   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 2.2.1 (Target): Usa LabelEncoder para convertir la columna 'species'\n",
    "# 1. Crea una instancia de LabelEncoder\n",
    "# 2. Ajústala y transfórmala sobre df['species']\n",
    "# 3. Guarda el resultado en una nueva columna, p.ej. 'species_encoded'\n",
    "\n",
    "# (Guarda el encoder para referencia futura)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE-HOT ENCODING   \n",
    "One-Hot Encoding (OHE) es una técnica de preprocesamiento que convierte una columna de datos categóricos en múltiples columnas binarias (0s y 1s).\n",
    "\n",
    "Cada categoría única en la columna original se convierte en su propia columna nueva, que actúa como un \"interruptor\" (0 = apagado, 1 = encendido).   \n",
    "\n",
    "La solución (OHE): OHE crea tres columnas (ej. isla_Torgersen, isla_Biscoe, isla_Dream).\n",
    "\n",
    "- Un pingüino de Biscoe será: [0, 1, 0]\n",
    "- Un pingüino de Dream será: [0, 0, 1]\n",
    "- Un pingüino de Torgersen será: [1, 0, 0]\n",
    "\n",
    "```python   \n",
    "# --- Aplicar One-Hot Encoding ---\n",
    "# pd.get_dummies() detecta automaticamente las columnas de\n",
    "# texto (tipo 'object') y las convierte.\n",
    "#\n",
    "# Nota: 'especie' es nuestro target, pero lo incluimos\n",
    "# solo para ver como lo codifica.\n",
    "df_codificado = pd.get_dummies(df)\n",
    "\n",
    "```\n",
    "```python    \n",
    "# --- OHE y la \"Trampa del Chupete\" (Dummy Variable Trap) ---\n",
    "#\n",
    "# Podemos observar que las columnas son redundantes.\n",
    "# Si 'isla_Biscoe'=0 e 'isla_Dream'=0, ya SABEMOS que 'isla_Torgersen' debe ser 1.\n",
    "#\n",
    "# Esta redundancia (multicolinealidad) puede causar problemas\n",
    "# en algunos modelos (como la Regresion Lineal).\n",
    "#\n",
    "# Solucion: Usar 'drop_first=True' para eliminar la primera\n",
    "# categoria de cada feature, convirtiendola en la 'base' (todo 0s).\n",
    "df_codificado_optimizado = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 2.2.2 (Features): Usa pd.get_dummies para convertir 'island' y 'sex'\n",
    "# Esto usará One-Hot Encoding, que es lo ideal para features categóricas en árboles.\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['island', 'sex'], drop_first=True)\n",
    "\n",
    "# Muestra el nuevo dataframe\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Preparar X (Features) e y (Target)\n",
    "\n",
    "**Tarea 3.1:** Define `y` como la columna codificada del target (`species_encoded`).\n",
    "**Tarea 3.2:** Define `X` como las columnas numéricas relevantes (las originales + las creadas por `get_dummies`). Asegúrate de NO incluir `species` (la original) ni `species_encoded` (el target) en `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 3.1: Define 'y'\n",
    "\n",
    "# HUECO 3.2: Define 'X'\n",
    "# Pista: puedes hacer X = df_encoded.drop(columns=['species', 'species_encoded'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: División de Datos (Train/Test)\n",
    "\n",
    "Divide `X` e `y` en conjuntos de entrenamiento y prueba. Usa un `test_size` de 0.3 y un `random_state` de 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 4: Importa train_test_split (si no lo hiciste) y divide los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Entrenamiento del Modelo\n",
    "\n",
    "Crea una instancia de `DecisionTreeClassifier`. Para evitar overfitting, asígnale un `max_depth` (profundidad máxima) de 4 y un `random_state` de 42. Luego, entrénalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 5: Crea el clasificador (clf) y entrénalo (fit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Evaluación del Modelo\n",
    "\n",
    "Usa el modelo entrenado para predecir sobre `X_test`. Calcula el `accuracy_score` y la `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 6: Realiza predicciones (y_pred) y evalúa el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7: (Opcional) Visualización\n",
    "\n",
    "Visualiza el árbol que has entrenado usando `plot_tree`. Necesitarás los nombres de las features (de `X.columns`) y los nombres de las clases (del `LabelEncoder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUECO 7 (Opcional): Visualiza el árbol\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plot_tree(clf,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          class_names=le.classes_, # 'le' es el nombre de tu LabelEncoder\n",
    "          feature_names=X.columns)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
