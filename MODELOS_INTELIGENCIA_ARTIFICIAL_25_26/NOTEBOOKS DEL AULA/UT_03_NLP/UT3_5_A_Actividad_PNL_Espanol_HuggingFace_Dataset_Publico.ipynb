{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Actividad práctica guiada: Desarrollo de un modelo de PLN en español con Hugging Face (dataset público)\n",
        "\n",
        "**Módulo:** Modelos de Inteligencia Artificial / Procesamiento del Lenguaje Natural  \n",
        "**Nivel:** Curso de Especialización en Inteligencia Artificial y Big Data (FP)  \n",
        "\n",
        "En esta actividad vas a **desarrollar y entrenar un modelo de análisis de sentimiento en español** utilizando:\n",
        "\n",
        "- Python  \n",
        "- La librería **Hugging Face Transformers**  \n",
        "- La librería **datasets** para cargar datos  \n",
        "- Un modelo preentrenado en español como base (transfer learning)\n",
        "- Un **dataset público** que no requiere permisos especiales: `mteb/spanish_sentiment`\n",
        "\n",
        "La actividad está pensada para que la puedas seguir paso a paso y, al mismo tiempo, te sirva como **material de estudio**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos de aprendizaje\n",
        "\n",
        "Al finalizar esta práctica serás capaz de:\n",
        "\n",
        "- Explicar qué es el **Procesamiento del Lenguaje Natural (PLN)** y qué tipos de tareas resuelve.\n",
        "- Identificar las partes principales de un **pipeline de PLN** moderno:\n",
        "  - Datos → Tokenizador → Modelo → Métricas → Predicciones.\n",
        "- Entender qué es un **modelo preentrenado** y qué es el **fine-tuning**.\n",
        "- Utilizar **Hugging Face** para:\n",
        "  - Cargar un conjunto de datos en español.\n",
        "  - Cargar un modelo preentrenado en español.\n",
        "  - Tokenizar texto y preparar tensores para el modelo.\n",
        "  - Entrenar (fine-tuning) un modelo de clasificación de texto.\n",
        "  - Evaluar el modelo y usarlo para predecir sentimientos de frases nuevas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Introducción teórica al PLN y a los Transformers\n",
        "\n",
        "### ¿Qué es el PLN?\n",
        "\n",
        "El **Procesamiento del Lenguaje Natural (PLN)** es el área de la Inteligencia Artificial que se encarga de que las máquinas puedan **entender, generar y manipular lenguaje humano** (texto o voz).\n",
        "\n",
        "Algunas tareas típicas de PLN son:\n",
        "\n",
        "- **Clasificación de texto:**  \n",
        "  - Ejemplo: detectar si una opinión es *positiva* o *negativa*.\n",
        "- **Análisis de sentimiento.**\n",
        "- **Detección de entidades (NER):** nombres de personas, lugares, organizaciones…\n",
        "- **Resumen automático de textos.**\n",
        "- **Traducción automática.**\n",
        "- **Pregunta-respuesta**, chatbots, etc.\n",
        "\n",
        "### De los modelos clásicos a los Transformers\n",
        "\n",
        "Históricamente se usaban modelos basados en:\n",
        "\n",
        "- Bolsas de palabras (*bag-of-words*), n-gramas…\n",
        "- Modelos estadísticos clásicos (Naive Bayes, SVM, etc.)\n",
        "\n",
        "Actualmente, los modelos más utilizados son los **Transformers**, como:\n",
        "\n",
        "- **BERT**, **RoBERTa**, **GPT**, etc.\n",
        "\n",
        "Características clave de los Transformers:\n",
        "\n",
        "- Trabajan con **representaciones vectoriales** de palabras (embeddings).\n",
        "- Usan un mecanismo llamado **atención (attention)** para ponderar la importancia de cada palabra en el contexto de la frase.\n",
        "- Se entrenan primero de forma **general** sobre grandes cantidades de texto (preentrenamiento) y luego se **ajustan (fine-tuning)** a tareas concretas como análisis de sentimiento, NER, etc.\n",
        "\n",
        "### ¿Qué es Hugging Face?\n",
        "\n",
        "**Hugging Face** es un ecosistema muy utilizado en PLN que ofrece:\n",
        "\n",
        "- La librería **`transformers`**, con modelos preentrenados listos para usar.\n",
        "- La librería **`datasets`**, con muchos conjuntos de datos listos para cargar.\n",
        "- El **Hugging Face Hub**, un repositorio online donde se publican modelos y datasets.\n",
        "\n",
        "En esta práctica usaremos:\n",
        "\n",
        "- Un modelo en español: `pysentimiento/robertuito-sentiment-analysis`, preentrenado para análisis de sentimiento.\n",
        "- Un dataset público de opiniones de hoteles en español: `mteb/spanish_sentiment`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Preparación del entorno\n",
        "\n",
        "En esta sección vamos a:\n",
        "\n",
        "1. Verificar la versión de Python.\n",
        "2. Instalar las librerías necesarias.\n",
        "3. Importar los módulos que utilizaremos.\n",
        "\n",
        "> **Nota:** solo necesitas ejecutar las celdas de código (las que tienen `In [ ]:` a la izquierda).  \n",
        "> Las celdas de tipo markdown (como esta) son texto explicativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e157571d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jordi/Documentos/Ribera/Curso_25_26/CEIABD/CEIABD_25_26/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Imports principales\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline,\n",
        ")\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n"
          ]
        }
      ],
      "source": [
        "# Comprobar la versión de Python (opcional)\n",
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f5caca",
      "metadata": {},
      "source": [
        "Conectar a Hugging Face\n",
        "1. Darse de alta en Hugging Face\n",
        "2. Crear un token\n",
        "3. Hacer loggin usando el token:  ```huggingface-cli login```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Si trabajas en un entorno limpio, descomenta y ejecuta estas líneas para instalar las dependencias.\n",
        "# En algunos entornos (como Google Colab) puede tardar unos minutos.\n",
        "\n",
        "# !pip install transformers datasets accelerate evaluate -q\n",
        "\n",
        "# Version más moderna:\n",
        "    \n",
        "# !pip install \"transformers[torch]\" datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3b0a6ea8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jordi/Documentos/Ribera/Curso_25_26/CEIABD/CEIABD_25_26/.venv/bin/python\n",
            "3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "print(sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0f655eee",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 955/955 [00:00<00:00, 44983.55 examples/s]\n",
            "Generating validation split: 100%|██████████| 137/137 [00:00<00:00, 26770.07 examples/s]\n",
            "Generating test split: 100%|██████████| 137/137 [00:00<00:00, 36511.61 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 955\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 137\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 137\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargar el dataset público de sentimiento en español\n",
        "dataset = load_dataset(\"mteb/spanish_sentiment\", \"default\")\n",
        "\n",
        "dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cargar un dataset de sentimiento en español (público)\n",
        "\n",
        "Vamos a usar el dataset **`mteb/spanish_sentiment`**, disponible en Hugging Face.  \n",
        "Este conjunto de datos contiene opiniones (principalmente sobre hoteles) en español etiquetadas con sentimiento:\n",
        "\n",
        "- `0` → generalmente **negativo**  \n",
        "- `1` → generalmente **positivo**  \n",
        "\n",
        "### ¿Por qué necesitamos un dataset etiquetado?\n",
        "\n",
        "Para entrenar un modelo de clasificación (supervisado) necesitamos:\n",
        "\n",
        "- **Entradas**: textos en español (reseñas, opiniones…).\n",
        "- **Salidas (etiquetas)**: la clase a la que pertenece cada texto (positiva o negativa).\n",
        "\n",
        "El modelo aprenderá a aproximar una función:\n",
        "\n",
        "\\[\n",
        "\\text{texto} \\longrightarrow \\text{etiqueta (0 = NEG, 1 = POS)}\n",
        "\\]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'text': 'Está situado en el centro de la ciudad , con todo lo más turístico a tu alrededor ( El Pilar , por ejemplo ) , y sitios para tomar algo .'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Veamos un ejemplo del conjunto de entrenamiento\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['label', 'text']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspeccionamos las columnas disponibles\n",
        "dataset[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño train: 955\n",
            "Tamaño validation: 137\n",
            "Tamaño test: 137\n"
          ]
        }
      ],
      "source": [
        "# Tamaño de cada partición\n",
        "print(\"Tamaño train:\", len(dataset[\"train\"]))\n",
        "print(\"Tamaño validation:\", len(dataset[\"validation\"]))\n",
        "print(\"Tamaño test:\", len(dataset[\"test\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análisis rápido de la distribución de clases\n",
        "\n",
        "Es buena práctica comprobar si el dataset está balanceado (si hay más ejemplos de una clase que de otra).  \n",
        "En este dataset la columna de etiquetas se llama **`label`** y contiene valores enteros (0, 1, ...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiquetas numéricas en train: [0, 1]\n",
            "Etiqueta 1: 790 ejemplos\n",
            "Etiqueta 0: 165 ejemplos\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Inspeccionamos las etiquetas numéricas presentes\n",
        "unique_labels = sorted(set(dataset[\"train\"][\"label\"]))\n",
        "print(\"Etiquetas numéricas en train:\", unique_labels)\n",
        "\n",
        "counter = Counter(dataset[\"train\"][\"label\"])\n",
        "for label_id, count in counter.items():\n",
        "    print(f\"Etiqueta {label_id}: {count} ejemplos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tokenización: convertir texto en números\n",
        "\n",
        "Los modelos tipo Transformer no trabajan directamente con texto, sino con **números**.\n",
        "\n",
        "El proceso de conversión de texto a tokens numéricos se llama **tokenización**.  \n",
        "Un **tokenizador** realiza varias tareas:\n",
        "\n",
        "- Divide el texto en unidades (palabras o subpalabras).\n",
        "- Asigna a cada token un **ID** entero.\n",
        "- Añade tokens especiales de inicio/fin, si son necesarios.\n",
        "- Gestiona la longitud máxima de la secuencia (`max_length`), truncando o rellenando (`padding`) cuando corresponde.\n",
        "\n",
        "En Hugging Face utilizamos **`AutoTokenizer`** para cargar automáticamente el tokenizador adecuado para un modelo concreto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [0, 697, 4095, 413, 6647, 15104, 474, 1383, 15879, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Nombre del modelo preentrenado en español que vamos a usar\n",
        "model_name = \"pysentimiento/robertuito-sentiment-analysis\"\n",
        "\n",
        "# Cargar el tokenizador asociado al modelo\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Probamos el tokenizador con una frase de ejemplo\n",
        "ejemplo_texto = \"Este curso de inteligencia artificial me parece increíble.\"\n",
        "tokens = tokenizer(ejemplo_texto)\n",
        "\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens: ['<s>', '▁este', '▁curso', '▁de', '▁inteligencia', '▁artificial', '▁me', '▁parece', '▁increíble.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "# Para ver los tokens de forma más legible\n",
        "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparar el dataset tokenizado\n",
        "\n",
        "Ahora definimos una función que reciba un lote de ejemplos (batch) y devuelva su versión tokenizada.  \n",
        "Usaremos `map` de `datasets` para aplicar esta función a todo el conjunto de datos.\n",
        "\n",
        "En este dataset, la columna de texto se llama **`text`**.\n",
        "\n",
        "Parámetros típicos del tokenizador:\n",
        "\n",
        "- `truncation=True` → recorta textos demasiado largos.\n",
        "- `padding=\"max_length\"` o `padding=True` → rellena textos cortos hasta una longitud estándar.\n",
        "- `max_length` → longitud máxima de tokens (por defecto, suele estar bien entre 128 y 256 para frases cortas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 955/955 [00:00<00:00, 13497.96 examples/s]\n",
            "Map: 100%|██████████| 137/137 [00:00<00:00, 6558.46 examples/s]\n",
            "Map: 100%|██████████| 137/137 [00:00<00:00, 7167.69 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 955\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 137\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 137\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Función de tokenización para aplicar al dataset completo\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False,  # el padding lo gestionaremos luego con el data collator\n",
        "        max_length=128,\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_batch, batched=True)\n",
        "\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Definir el modelo de clasificación de texto\n",
        "\n",
        "Vamos a cargar un modelo preentrenado en español para análisis de sentimiento y, además, vamos a ajustarlo (fine-tuning) usando nuestro dataset.\n",
        "\n",
        "- Usamos **`AutoModelForSequenceClassification`** para cargar un modelo de clasificación de secuencias.\n",
        "- Le indicamos cuántas etiquetas (`num_labels`) hay.\n",
        "- Definimos un diccionario `id2label` y `label2id` para que las salidas sean más interpretables.\n",
        "\n",
        "En este dataset las etiquetas son valores enteros; definiremos nombres de clase sencillos:\n",
        "\n",
        "- 0 → `NEG` (negativo)  \n",
        "- 1 → `POS` (positivo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombres de etiquetas: ['NEG', 'POS']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Definimos los nombres de las etiquetas\n",
        "unique_labels = sorted(set(dataset[\"train\"][\"label\"]))\n",
        "\n",
        "if len(unique_labels) == 2:\n",
        "    label_names = [\"NEG\", \"POS\"]\n",
        "else:\n",
        "    label_names = [f\"CLASS_{i}\" for i in unique_labels]\n",
        "\n",
        "print(\"Nombres de etiquetas:\", label_names)\n",
        "\n",
        "num_labels = len(label_names)\n",
        "id2label = {i: label_names[i] for i in range(num_labels)}\n",
        "label2id = {label_names[i]: i for i in range(num_labels)}\n",
        "\n",
        "# Cargar el modelo de clasificación basado en el modelo preentrenado\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,               # \"pysentimiento/robertuito-sentiment-analysis\"\n",
        "    num_labels=num_labels,    # 2\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,  # <- CLAVE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Preparar el entrenamiento (fine-tuning)\n",
        "\n",
        "Para entrenar el modelo necesitamos:\n",
        "\n",
        "1. **Datos tokenizados** en forma de tensores (input_ids, attention_mask, labels).\n",
        "2. Un **data collator**, que se encargue de aplicar padding dinámico en cada batch.\n",
        "3. Una configuración de entrenamiento (`TrainingArguments`):\n",
        "   - Número de épocas (`num_train_epochs`).\n",
        "   - Tamaño de batch (`per_device_train_batch_size`).\n",
        "   - Tasa de aprendizaje (`learning_rate`).\n",
        "   - Directorio de salida, etc.\n",
        "4. Un **Trainer** que orqueste el proceso de entrenamiento y evaluación.\n",
        "\n",
        "Además, definiremos métricas de evaluación, como:\n",
        "\n",
        "- **Accuracy (exactitud)**.\n",
        "- **F1** macro, útil cuando las clases están desbalanceadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 4.20kB [00:00, 4.43MB/s]\n",
            "Downloading builder script: 6.79kB [00:00, 5.48MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Data collator: aplica padding dinámico para que los batch tengan la misma longitud\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Cargamos las métricas\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1_macro\": f1_macro,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"resultado_sentiment_es_public\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    # sin evaluation_strategy, ni save_strategy,\n",
        "    # ni load_best_model_at_end, ni metric_for_best_model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_69626/4044864829.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Definimos el Trainer que gestionará el entrenamiento\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenar el modelo\n",
        "\n",
        "> **Aviso:** esta celda puede tardar varios minutos en función del hardware disponible (CPU vs GPU).  \n",
        "> Si estás en un entorno con GPU (por ejemplo, Google Colab), asegúrate de activarla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 00:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=180, training_loss=0.10611737569173177, metrics={'train_runtime': 26.4207, 'train_samples_per_second': 108.438, 'train_steps_per_second': 6.813, 'total_flos': 88374481274160.0, 'train_loss': 0.10611737569173177, 'epoch': 3.0})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entrenamiento (fine-tuning)\n",
        "train_result = trainer.train()\n",
        "\n",
        "train_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluación del modelo\n",
        "\n",
        "Una vez entrenado el modelo, es importante evaluarlo en el **conjunto de test**, que el modelo no ha visto durante el entrenamiento ni la validación.\n",
        "\n",
        "Así obtenemos una estimación más realista de su rendimiento en datos nuevos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.21367159485816956,\n",
              " 'eval_accuracy': 0.9562043795620438,\n",
              " 'eval_f1_macro': 0.9242256637168141,\n",
              " 'eval_runtime': 0.3531,\n",
              " 'eval_samples_per_second': 388.041,\n",
              " 'eval_steps_per_second': 14.162,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
        "test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Uso del modelo entrenado para hacer predicciones\n",
        "\n",
        "Vamos a probar el modelo con frases inventadas para ver qué sentimiento predice.  \n",
        "\n",
        "Utilizaremos la función `pipeline` de Hugging Face, que simplifica mucho el proceso de inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase: Este curso de inteligencia artificial me encanta, aprendo muchísimo.\n",
            "Predicción: POS, score=0.9979\n",
            "------------------------------------------------------------\n",
            "Frase: No me gusta nada este producto, es una pérdida de dinero.\n",
            "Predicción: NEG, score=0.9923\n",
            "------------------------------------------------------------\n",
            "Frase: La película estuvo bien, pero tampoco fue espectacular.\n",
            "Predicción: NEG, score=0.8505\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Creamos un pipeline de análisis de sentimiento en español usando nuestro modelo entrenado\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=trainer.model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Probamos con algunas frases\n",
        "frases = [\n",
        "    \"Este curso de inteligencia artificial me encanta, aprendo muchísimo.\",\n",
        "    \"No me gusta nada este producto, es una pérdida de dinero.\",\n",
        "    \"La película estuvo bien, pero tampoco fue espectacular.\",\n",
        "]\n",
        "\n",
        "for frase in frases:\n",
        "    resultado = sentiment_analyzer(frase)[0]\n",
        "    print(f\"Frase: {frase}\")\n",
        "    print(f\"Predicción: {resultado['label']}, score={resultado['score']:.4f}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Resumen teórico del flujo completo\n",
        "\n",
        "A continuación se resume el flujo de trabajo que has seguido:\n",
        "\n",
        "1. **Definición de la tarea de PLN**  \n",
        "   - Clasificación de texto: análisis de sentimiento en español (NEG / POS).\n",
        "\n",
        "2. **Selección de un modelo preentrenado**  \n",
        "   - Modelo base: `pysentimiento/robertuito-sentiment-analysis`, entrenado previamente sobre grandes cantidades de texto en español (especialmente tweets).\n",
        "\n",
        "3. **Carga del dataset etiquetado**  \n",
        "   - Dataset: `mteb/spanish_sentiment`, con ejemplos de texto en español y etiquetas de sentimiento binario (0 = negativo, 1 = positivo).\n",
        "\n",
        "4. **Preprocesamiento y tokenización**  \n",
        "   - Conversión de texto a tokens e IDs numéricos con `AutoTokenizer`.\n",
        "   - Aplicación de truncado y gestión de longitud máxima.\n",
        "\n",
        "5. **Definición del modelo de clasificación**  \n",
        "   - `AutoModelForSequenceClassification` añade una capa de clasificación encima del modelo base.\n",
        "   - `num_labels`, `id2label` y `label2id` definen el espacio de salida.\n",
        "\n",
        "6. **Configuración del entrenamiento (fine-tuning)**  \n",
        "   - Parámetros de entrenamiento (épocas, batch size, learning rate…).\n",
        "   - Definición de métricas (accuracy, F1 macro).\n",
        "   - Uso de `Trainer` para gestionar el ciclo de entrenamiento y evaluación.\n",
        "\n",
        "7. **Evaluación del modelo**  \n",
        "   - Cálculo de métricas en el conjunto de test.\n",
        "\n",
        "8. **Inferencia (uso en producción)**  \n",
        "   - Creación de un `pipeline` de análisis de sentimiento para predecir etiquetas sobre nuevos textos.\n",
        "\n",
        "Este esquema es muy similar para otras tareas de PLN con Transformers (NER, resumen, traducción, etc.), cambiando:\n",
        "\n",
        "- El tipo de modelo y el `pipeline` (por ejemplo, `ner`, `summarization`, `translation`).\n",
        "- El dataset y las etiquetas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Actividades propuestas para afianzar el aprendizaje\n",
        "\n",
        "1. **Cambiar el modelo base**  \n",
        "   - Busca en Hugging Face otro modelo en español (por ejemplo, basado en RoBERTa o BERT multilingüe) y repite el proceso de entrenamiento.  \n",
        "   - Compara las métricas obtenidas (accuracy, F1).\n",
        "\n",
        "2. **Modificar hiperparámetros**  \n",
        "   - Cambia el número de épocas (`num_train_epochs`), el tamaño de batch o la tasa de aprendizaje.  \n",
        "   - Observa cómo afecta al rendimiento y al tiempo de entrenamiento.\n",
        "\n",
        "3. **Análisis de errores**  \n",
        "   - Filtra ejemplos donde el modelo falle (predicción distinta a la etiqueta real).  \n",
        "   - Lee esos textos y analiza por qué crees que el modelo se equivoca.\n",
        "\n",
        "4. **Ampliar el preprocesamiento**  \n",
        "   - Añade una fase previa de limpieza del texto (por ejemplo, eliminar URLs, menciones, emojis…).  \n",
        "   - Vuelve a entrenar y compara resultados.\n",
        "\n",
        "5. **Crear tu propio pequeño dataset**  \n",
        "   - Crea un CSV con frases en español y una etiqueta de sentimiento (por ejemplo, `NEG` o `POS`).  \n",
        "   - Carga ese CSV con `load_dataset(\"csv\", data_files=...)` y entrena un modelo con tus propios datos.\n",
        "\n",
        "---\n",
        "\n",
        "Con esta práctica tienes una **plantilla completa** para desarrollar modelos de PLN en español usando Hugging Face y un **dataset público**.  \n",
        "A partir de aquí, puedes adaptar el código a otras tareas y datasets, manteniendo la misma estructura general."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
