{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad práctica guiada: Desarrollo de un modelo de PLN en español con Hugging Face\n",
    "\n",
    "**Módulo:** Modelos de Inteligencia Artificial / Procesamiento del Lenguaje Natural  \n",
    "**Curso:** Curso de Especialización en Inteligencia Artificial y Big Data (FP)  \n",
    "\n",
    "En esta actividad vas a **desarrollar y entrenar un modelo de análisis de sentimiento en español** utilizando:\n",
    "\n",
    "- Python  \n",
    "- La librería **Hugging Face Transformers**  \n",
    "- La librería **datasets** para cargar datos  \n",
    "- Un modelo preentrenado en español como base (transfer learning)\n",
    "\n",
    "La actividad está pensada para seguirla paso a paso y, al mismo tiempo, que sirva como **material de estudio**."
   ],
   "id": "55d95ae383c48026"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar esta práctica serás capaz de:\n",
    "\n",
    "- Explicar qué es el **Procesamiento del Lenguaje Natural (PLN)** y qué tipos de tareas resuelve.\n",
    "- Identificar las partes principales de un **pipeline de PLN** moderno:\n",
    "  - Datos → Tokenizador → Modelo → Métricas → Predicciones.\n",
    "- Entender qué es un **modelo preentrenado** y qué es el **fine-tuning**.\n",
    "- Utilizar **Hugging Face** para:\n",
    "  - Cargar un conjunto de datos en español.\n",
    "  - Cargar un modelo preentrenado en español.\n",
    "  - Tokenizar texto y preparar tensores para el modelo.\n",
    "  - Entrenar (fine-tuning) un modelo de clasificación de texto.\n",
    "  - Evaluar el modelo y usarlo para predecir sentimientos de frases nuevas."
   ],
   "id": "2551bb3e8f2c4395"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introducción teórica al PLN y a los Transformers\n",
    "\n",
    "### ¿Qué es el PLN?\n",
    "\n",
    "El **Procesamiento del Lenguaje Natural (PLN)** es el área de la Inteligencia Artificial que se encarga de que las máquinas puedan **entender, generar y manipular lenguaje humano** (texto o voz).\n",
    "\n",
    "Algunas tareas típicas de PLN son:\n",
    "\n",
    "- **Clasificación de texto:**  \n",
    "  - Ejemplo: detectar si una opinión es *positiva*, *negativa* o *neutra*.\n",
    "- **Análisis de sentimiento.**\n",
    "- **Detección de entidades (NER):** nombres de personas, lugares, organizaciones…\n",
    "- **Resumen automático de textos.**\n",
    "- **Traducción automática.**\n",
    "- **Pregunta-respuesta**, chatbots, etc.\n",
    "\n",
    "### De los modelos clásicos a los Transformers\n",
    "\n",
    "Históricamente se usaban modelos basados en:\n",
    "\n",
    "- Bolsas de palabras (*bag-of-words*), n-gramas…\n",
    "- Modelos estadísticos clásicos (Naive Bayes, SVM, etc.)\n",
    "\n",
    "Actualmente, los modelos más utilizados son los **Transformers**, como:\n",
    "\n",
    "- **BERT**, **RoBERTa**, **GPT**, etc.\n",
    "\n",
    "Características clave de los Transformers:\n",
    "\n",
    "- Trabajan con **representaciones vectoriales** de palabras (embeddings).\n",
    "- Usan un mecanismo llamado **atención (attention)** para ponderar la importancia de cada palabra en el contexto de la frase.\n",
    "- Se entrenan primero de forma **general** sobre grandes cantidades de texto (preentrenamiento) y luego se **ajustan (fine-tuning)** a tareas concretas como análisis de sentimiento, NER, etc.\n",
    "\n",
    "### ¿Qué es Hugging Face?\n",
    "\n",
    "**Hugging Face** es un ecosistema muy utilizado en PLN que ofrece:\n",
    "\n",
    "- La librería **`transformers`**, con modelos preentrenados listos para usar.\n",
    "- La librería **`datasets`**, con muchos conjuntos de datos listos para cargar.\n",
    "- El **Hugging Face Hub**, un repositorio online donde se publican modelos y datasets.\n",
    "\n",
    "En esta práctica usaremos:\n",
    "\n",
    "- Un modelo en español: `pysentimiento/robertuito-sentiment-analysis`, preentrenado para análisis de sentimiento.\n",
    "- Un dataset de opiniones en español: `pysentimiento/es_sentiment`."
   ],
   "id": "69a608f8fd923b8a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación del entorno\n",
    "\n",
    "En esta sección vamos a:\n",
    "\n",
    "1. Verificar la versión de Python.\n",
    "2. Instalar las librerías necesarias.\n",
    "3. Importar los módulos que utilizaremos.\n",
    "\n",
    "> **Nota:** solo necesitas ejecutar las celdas de código (las que tienen `In [ ]:` a la izquierda).  \n",
    "> Las celdas de tipo markdown (como esta) son texto explicativo."
   ],
   "id": "7fec8658dc8de50"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "# Comprobar la versión de Python (opcional)\n",
    "import sys\n",
    "print(sys.version)"
   ],
   "id": "c3f5ab7726ffdb71"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si se trabaja en un entorno limpio, descomentar y ejecutar estas líneas para instalar las dependencias.\n",
    "# En algunos entornos (como Google Colab) puede tardar unos minutos.\n",
    "\n",
    "# !pip install transformers datasets accelerate evaluate -q"
   ],
   "id": "a9eaf4ef4945fae2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principales\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np"
   ],
   "id": "28d5962d9976e702"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar un dataset de sentimiento en español\n",
    "\n",
    "Vamos a usar el dataset **`pysentimiento/es_sentiment`**, disponible en Hugging Face.  \n",
    "Este conjunto de datos contiene textos en español etiquetados con sentimiento:\n",
    "\n",
    "- `POS` → positivo  \n",
    "- `NEG` → negativo  \n",
    "- `NEU` → neutro  \n",
    "\n",
    "### ¿Por qué necesitamos un dataset etiquetado?\n",
    "\n",
    "Para entrenar un modelo de clasificación (supervisado) necesitamos:\n",
    "\n",
    "- **Entradas**: textos en español (tweets, reseñas, opiniones…).\n",
    "- **Salidas (etiquetas)**: la clase a la que pertenece cada texto (positiva, negativa, neutra).\n",
    "\n",
    "El modelo aprenderá a aproximar una función:\n",
    "\n",
    "\\[\n",
    "\\text{texto} \\longrightarrow \\text{etiqueta (POS, NEG, NEU)}\n",
    "\\]"
   ],
   "id": "de93ce1bf88d2b1f"
  },
  {
   "cell_type": "markdown",
   "id": "9a09b8c7",
   "metadata": {},
   "source": [
    "A la espera de concesión de permiso de acceso al REPO!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de sentimiento en español\n",
    "dataset = load_dataset(\"pysentimiento/es_sentiment\")\n",
    "\n",
    "dataset"
   ],
   "id": "d5519e36e3cb7436"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos un ejemplo del conjunto de entrenamiento\n",
    "dataset[\"train\"][0]"
   ],
   "id": "fc552d8e08e25e66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionamos las columnas disponibles\n",
    "dataset[\"train\"].column_names"
   ],
   "id": "b71a930e572d082f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de cada partición\n",
    "print(\"Tamaño train:\", len(dataset[\"train\"]))\n",
    "print(\"Tamaño validation:\", len(dataset[\"validation\"]))\n",
    "print(\"Tamaño test:\", len(dataset[\"test\"]))"
   ],
   "id": "b32f98dbcee85855"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis rápido de la distribución de clases\n",
    "\n",
    "Es buena práctica comprobar si el dataset está balanceado (si hay más ejemplos de una clase que de otra)."
   ],
   "id": "272c9c54dec39eba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_names = dataset[\"train\"].features[\"label\"].names  # nombres de las etiquetas\n",
    "print(\"Etiquetas:\", label_names)\n",
    "\n",
    "counter = Counter(dataset[\"train\"][\"label\"])\n",
    "for label_id, count in counter.items():\n",
    "    print(f\"Etiqueta {label_names[label_id]} ({label_id}): {count} ejemplos\")"
   ],
   "id": "132b28cdeed73e95"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenización: convertir texto en números\n",
    "\n",
    "Los modelos tipo Transformer no trabajan directamente con texto, sino con **números**.\n",
    "\n",
    "El proceso de conversión de texto a tokens numéricos se llama **tokenización**.  \n",
    "Un **tokenizador** realiza varias tareas:\n",
    "\n",
    "- Divide el texto en unidades (palabras o subpalabras).\n",
    "- Asigna a cada token un **ID** entero.\n",
    "- Añade tokens especiales de inicio/fin, si son necesarios.\n",
    "- Gestiona la longitud máxima de la secuencia (`max_length`), truncando o rellenando (`padding`) cuando corresponde.\n",
    "\n",
    "En Hugging Face utilizamos **`AutoTokenizer`** para cargar automáticamente el tokenizador adecuado para un modelo concreto."
   ],
   "id": "d1ded0db391ea17d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre del modelo preentrenado en español que vamos a usar\n",
    "model_name = \"pysentimiento/robertuito-sentiment-analysis\"\n",
    "\n",
    "# Cargar el tokenizador asociado al modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Probamos el tokenizador con una frase de ejemplo\n",
    "ejemplo_texto = \"Este curso de inteligencia artificial me parece increíble.\"\n",
    "tokens = tokenizer(ejemplo_texto)\n",
    "\n",
    "tokens"
   ],
   "id": "70f21dd8b0fe66e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver los tokens de forma más legible\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"]))"
   ],
   "id": "9fdbac583838318c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar el dataset tokenizado\n",
    "\n",
    "Ahora definimos una función que reciba un lote de ejemplos (batch) y devuelva su versión tokenizada.  \n",
    "Usaremos `map` de `datasets` para aplicar esta función a todo el conjunto de datos.\n",
    "\n",
    "Parámetros típicos del tokenizador:\n",
    "\n",
    "- `truncation=True` → recorta textos demasiado largos.\n",
    "- `padding=\"max_length\"` o `padding=True` → rellena textos cortos hasta una longitud estándar.\n",
    "- `max_length` → longitud máxima de tokens (por defecto, suele estar bien entre 128 y 256 para frases cortas)."
   ],
   "id": "3f1df8027831e67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de tokenización para aplicar al dataset completo\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,  # el padding lo gestionaremos luego con el data collator\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_batch, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ],
   "id": "703ca9a5ab07539c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definir el modelo de clasificación de texto\n",
    "\n",
    "Vamos a cargar un modelo preentrenado en español para análisis de sentimiento y, además, vamos a ajustarlo (fine-tuning) usando nuestro dataset.\n",
    "\n",
    "- Usamos **`AutoModelForSequenceClassification`** para cargar un modelo de clasificación de secuencias.\n",
    "- Le indicamos cuántas etiquetas (`num_labels`) hay.\n",
    "- Opcionalmente, podemos pasar el diccionario `id2label` y `label2id` para que las salidas sean más interpretables."
   ],
   "id": "82f4a0120d16a350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el mapeo entre IDs y nombres de etiquetas\n",
    "num_labels = len(label_names)\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {label: i for i, label in enumerate(label_names)}\n",
    "\n",
    "# Cargar el modelo de clasificación basado en el modelo preentrenado\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ],
   "id": "9dbb1d6e0587ff03"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar el entrenamiento (fine-tuning)\n",
    "\n",
    "Para entrenar el modelo necesitamos:\n",
    "\n",
    "1. **Datos tokenizados** en forma de tensores (input_ids, attention_mask, labels).\n",
    "2. Un **data collator**, que se encargue de aplicar padding dinámico en cada batch.\n",
    "3. Una configuración de entrenamiento (`TrainingArguments`):\n",
    "   - Número de épocas (`num_train_epochs`).\n",
    "   - Tamaño de batch (`per_device_train_batch_size`).\n",
    "   - Tasa de aprendizaje (`learning_rate`).\n",
    "   - Directorio de salida, etc.\n",
    "4. Un **Trainer** que orqueste el proceso de entrenamiento y evaluación.\n",
    "\n",
    "Además, definiremos métricas de evaluación, como:\n",
    "\n",
    "- **Accuracy (exactitud)**.\n",
    "- **F1** macro, útil cuando las clases están desbalanceadas."
   ],
   "id": "dcf8b87f9f13896b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator: aplica padding dinámico para que los batch tengan la misma longitud\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Cargamos las métricas\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro,\n",
    "    }"
   ],
   "id": "ad5f6db2c9859f34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"resultado_sentiment_es\",\n",
    "    evaluation_strategy=\"epoch\",         # evaluar al final de cada época\n",
    "    save_strategy=\"epoch\",               # guardar modelo al final de cada época\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")"
   ],
   "id": "9728736a734212fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el Trainer que gestionará el entrenamiento\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "7aca2fd210e1f450"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo\n",
    "\n",
    "> **Aviso:** esta celda puede tardar varios minutos en función del hardware disponible (CPU vs GPU).  \n",
    "> Si estás en un entorno con GPU (por ejemplo, Google Colab), asegúrate de activarla."
   ],
   "id": "108495892c59f91e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento (fine-tuning)\n",
    "train_result = trainer.train()\n",
    "\n",
    "train_result"
   ],
   "id": "54abc06a572c606"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluación del modelo\n",
    "\n",
    "Una vez entrenado el modelo, es importante evaluarlo en el **conjunto de test**, que el modelo no ha visto durante el entrenamiento ni la validación.\n",
    "\n",
    "Así obtenemos una estimación más realista de su rendimiento en datos nuevos."
   ],
   "id": "9ee7701b2bd1b2ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "test_metrics"
   ],
   "id": "e5e2064764d5b711"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Uso del modelo entrenado para hacer predicciones\n",
    "\n",
    "Vamos a probar el modelo con frases inventadas para ver qué sentimiento predice.  \n",
    "\n",
    "Utilizaremos la función `pipeline` de Hugging Face, que simplifica mucho el proceso de inferencia."
   ],
   "id": "5834e9f68f4c4a85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un pipeline de análisis de sentimiento en español usando nuestro modelo entrenado\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Probamos con algunas frases\n",
    "frases = [\n",
    "    \"Este curso de inteligencia artificial me encanta, aprendo muchísimo.\",\n",
    "    \"No me gusta nada este producto, es una pérdida de dinero.\",\n",
    "    \"La película estuvo bien, pero tampoco fue espectacular.\",\n",
    "]\n",
    "\n",
    "for frase in frases:\n",
    "    resultado = sentiment_analyzer(frase)[0]\n",
    "    print(f\"Frase: {frase}\")\n",
    "    print(f\"Predicción: {resultado['label']}, score={resultado['score']:.4f}\")\n",
    "    print(\"-\" * 60)"
   ],
   "id": "6e3bf08a225a2f26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen teórico del flujo completo\n",
    "\n",
    "A continuación se resume el flujo de trabajo que has seguido:\n",
    "\n",
    "1. **Definición de la tarea de PLN**  \n",
    "   - Clasificación de texto: análisis de sentimiento en español (POS, NEG, NEU).\n",
    "\n",
    "2. **Selección de un modelo preentrenado**  \n",
    "   - Modelo base: `pysentimiento/robertuito-sentiment-analysis`, entrenado previamente sobre grandes cantidades de texto en español (especialmente tweets).\n",
    "\n",
    "3. **Carga del dataset etiquetado**  \n",
    "   - Dataset: `pysentimiento/es_sentiment`, con ejemplos de texto en español y sus etiquetas de sentimiento.\n",
    "\n",
    "4. **Preprocesamiento y tokenización**  \n",
    "   - Conversión de texto a tokens e IDs numéricos con `AutoTokenizer`.\n",
    "   - Aplicación de truncado y gestión de longitud máxima.\n",
    "\n",
    "5. **Definición del modelo de clasificación**  \n",
    "   - `AutoModelForSequenceClassification` añade una capa de clasificación encima del modelo base.\n",
    "   - `num_labels`, `id2label` y `label2id` definen el espacio de salida.\n",
    "\n",
    "6. **Configuración del entrenamiento (fine-tuning)**  \n",
    "   - Parámetros de entrenamiento (épocas, batch size, learning rate…).\n",
    "   - Definición de métricas (accuracy, F1 macro).\n",
    "   - Uso de `Trainer` para gestionar el ciclo de entrenamiento y evaluación.\n",
    "\n",
    "7. **Evaluación del modelo**  \n",
    "   - Cálculo de métricas en el conjunto de test.\n",
    "\n",
    "8. **Inferencia (uso en producción)**  \n",
    "   - Creación de un `pipeline` de análisis de sentimiento para predecir etiquetas sobre nuevos textos.\n",
    "\n",
    "Este esquema es muy similar para otras tareas de PLN con Transformers (NER, resumen, traducción, etc.), cambiando:\n",
    "\n",
    "- El tipo de modelo y el `pipeline` (por ejemplo, `ner`, `summarization`, `translation`).\n",
    "- El dataset y las etiquetas."
   ],
   "id": "3f8b98c454540687"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Actividades propuestas para afianzar el aprendizaje\n",
    "\n",
    "1. **Cambiar el modelo base**  \n",
    "   - Busca en Hugging Face otro modelo en español (por ejemplo, basado en RoBERTa o BERT multilingüe) y repite el proceso de entrenamiento.  \n",
    "   - Compara las métricas obtenidas (accuracy, F1).\n",
    "\n",
    "2. **Modificar hiperparámetros**  \n",
    "   - Cambia el número de épocas (`num_train_epochs`), el tamaño de batch o la tasa de aprendizaje.  \n",
    "   - Observa cómo afecta al rendimiento y al tiempo de entrenamiento.\n",
    "\n",
    "3. **Análisis de errores**  \n",
    "   - Filtra ejemplos donde el modelo falle (predicción distinta a la etiqueta real).  \n",
    "   - Lee esos textos y analiza por qué crees que el modelo se equivoca.\n",
    "\n",
    "4. **Ampliar el preprocesamiento**  \n",
    "   - Añade una fase previa de limpieza del texto (por ejemplo, eliminar URLs, menciones, emojis…).  \n",
    "   - Vuelve a entrenar y compara resultados.\n",
    "\n",
    "5. **Crear tu propio pequeño dataset**  \n",
    "   - Crea un CSV con frases en español y una etiqueta de sentimiento (por ejemplo, `POS` o `NEG`).  \n",
    "   - Carga ese CSV con `load_dataset(\"csv\", data_files=...)` y entrena un modelo con tus propios datos.\n",
    "\n",
    "---\n",
    "\n",
    "Con esta práctica tienes una **plantilla completa** para desarrollar modelos de PLN en español usando Hugging Face.  \n",
    "A partir de aquí, puedes adaptar el código a otras tareas y datasets, manteniendo la misma estructura general."
   ],
   "id": "fead0783fe58df93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
