{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b2f99f",
   "metadata": {},
   "source": [
    "# RED NEURONAL CONVOLUCIONAL - EJERCICIO GUIADO - DATASET MINST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02245467",
   "metadata": {},
   "source": [
    "## INFORMACI√ìN SOBRE EL DATASET    \n",
    "\n",
    "El dataset que usaremos en este ejercicio es el dataset MNIST, y contiene un total de 70,000 im√°genes (60,000 de entrenamiento y 10,000 de validaci√≥n), cada una de ellas en escala de gris y con un tama√±o de 28√ó28.\n",
    "\n",
    "Las im√°genes contienen los d√≠gitos del 0 al 9, escritos por diferentes personas:   \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./img/ejemplos-imagenes-set-mnist.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f61e9",
   "metadata": {},
   "source": [
    "El objetivo es implementar un clasificador capaz de determinar a qu√© d√≠gito corresponde cada imagen, independientemente de c√≥mo este haya sido escrito.   \n",
    "\n",
    "Para ello usaremos **LeNet**, la arquitectura precursora de todas las Redes Convolucionales usadas en la actualidad y cuyo esquema se puede ver a continuaci√≥n:   \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./img/red-convolucional-lenet.png\" width=\"1000\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbb98e",
   "metadata": {},
   "source": [
    "En esta arquitectura se observan los siguientes componentes:    \n",
    "\n",
    "- La entrada a esta red es una imagen de 28√ó28, que contendr√° un d√≠gito escrito a mano.\n",
    "- Posteriormente la red usa una serie de capas convolucionales y de max-pooling, para de manera progresiva extraer las caracter√≠sticas m√°s relevantes de cada imagen. A medida que vamos m√°s profundo en estas capas convolucionales, el ancho y alto de las im√°genes resultantes va disminuyendo (pasando de 28√ó28 a 24√ó24, 12√ó12, 8√ó8 y 4√ó4) pero a la vez la profundidad de las mismas va en aumento (pasando de 1 a 6 y a 16). Esta profundidad indica precisamente que en las capas m√°s ocultas se extraen m√°s caracter√≠sticas de cada imagen.\n",
    "- El objetivo del entrenamiento de esta red convolucional es precisamente entrenar los filtros CONV1 y CONV2 para que ‚Äúaprendan‚Äù a extraer las caracter√≠sticas relevantes de cada una de las 60,000 im√°genes de entrenamiento.\n",
    "- La salida de las capas convolucionales es un volumen de 4x4x16, que contiene las caracter√≠sticas m√°s relevantes de las im√°genes de entrenamiento.\n",
    "- En la etapa de salida, y para realizar la clasificaci√≥n, se usa una peque√±a Red Neuronal. Para ello primero se ‚Äúaplana‚Äù el volumen de 4x4x16 de la etapa anterior, obteniendo as√≠ un vector de 256√ó1. Este es llevado a la Red Neuronal que tiene dos capas ocultas, la primera con 120 neuronas y la segunda con 84.\n",
    "- Finalmente, la categor√≠a a la que pertenece cada imagen es determinada por la capa de salida de esta red, que consiste en una funci√≥n de activaci√≥n softmax con 10 salidas (correspondientes a cada una de las posibles categor√≠as, los d√≠gitos del 0 al 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03723be4",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac54f4",
   "metadata": {},
   "source": [
    "### 1. Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4139e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist # Importamos el conjunto de datos MNIST\n",
    "from tensorflow.keras.utils import to_categorical # Utilidades para el preprocesamiento de datos\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428600b",
   "metadata": {},
   "source": [
    "### 2. Cargamos conjunto de datos a TRAIN y TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3424b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "TRAIN data shape: (60000, 28, 28)\n",
      "TEST data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"TRAIN data shape: {x_train.shape}\")\n",
    "print(f\"TEST data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9c97d",
   "metadata": {},
   "source": [
    "### 3. Normalizaci√≥n de las im√°genes   \n",
    "\n",
    "Se procede a normalizar cada una de las im√°genes, para que cada pixel est√© en el rango de 0 a 1 (y no de 0 a 255). Esto es necesario para garantizar la convergencia del algoritmo del Gradiente Descendente durante el entrenamiento. De no realizar la normalizaci√≥n se producir√≠a lo siguiente:   \n",
    "\n",
    "üîπ 1. El gradiente descendente ser√≠a m√°s inestable\n",
    "\n",
    "El algoritmo que ajusta los pesos (gradiente descendente) funciona calculando cambios peque√±os. Si las entradas son muy grandes (255), los cambios pueden ser:\n",
    "\n",
    "- demasiado bruscos\n",
    "- la red tarda mucho m√°s en aprender\n",
    "- incluso puede no converger (no aprender nada)\n",
    "\n",
    "üîπ 2. Los pesos de las capas se desbalancean\n",
    "\n",
    "Los pesos de la red empiezan siendo n√∫meros peque√±itos (por ejemplo 0.01). Si multiplicas esos pesos por valores enormes como 255, todo se ‚Äúdispara‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd92bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab6cf4",
   "metadata": {},
   "source": [
    "A continuaci√≥n se convierten las etiquetas de los sets de entrenamiento y validaci√≥n al formato **one-hot**, usando la funci√≥n ¬´to_categorical(...)¬ª. En este formato, cada categor√≠a estar√° representada con una secuencia de n√∫meros binarios: por ejemplo los d√≠gitos que pertenezcan a la categor√≠a 4 ser√°n representados por la secuencia [0,0,0,0,1,0,0,0,0,0] (de ah√≠ el nombre one-hot: s√≥lo uno de los d√≠gitos ser√° diferente de cero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb19aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclases = 10\n",
    "y_train = to_categorical(y_train,nclases)\n",
    "y_test = to_categorical(y_test,nclases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c31db5",
   "metadata": {},
   "source": [
    "Visualizaci√≥n de una imagen de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b96ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nimagen = 100\n",
    "plt.imshow(x_train[nimagen,:].reshape(28,28), cmap='gray_r')\n",
    "plt.title('Imagen ejemplo - Categor√≠a: ' + str(np.argmax(y_train[nimagen])))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba32fb4",
   "metadata": {},
   "source": [
    "Finalmente, se reajustan las im√°genes de entrenamiento y validaci√≥n, para indicar expl√≠citamente a Keras que cada imagen tendr√° un solo canal de informaci√≥n (por tratarse de im√°genes en escala de gris).   \n",
    "\n",
    "Para esto se utiliza la funci√≥n ¬´reshape¬ª de Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1237f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d6ddf",
   "metadata": {},
   "source": [
    "### 4. Construcci√≥n de la arquitectura del modelo de red CNN   \n",
    "\n",
    "La arquitectura de la red debe seguir las caracter√≠sticas reflejadas en la siguiente tabla:   \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./img/arquitecturaLeNet_tabla.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el modelo\n",
    "\n",
    "model = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adimos capa convolucional al modelo\n",
    "\n",
    "model.add(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adimos capa pooling al modelo\n",
    "\n",
    "model.add(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguimos a√±adiendo capas al modelo de tipo Conv2D y MaxPooling2D, siguiendo la estructura de la tabla anterior.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanamos las matrices 2D a vectores 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adimos la primera capa densa (fully connected) (120 neuronas y funci√≥n de activaci√≥n ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adimos la segunda capa densa (fully connected) (84 neuronas y funci√≥n de activaci√≥n ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268dd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adimos la capa densa de salida con funci√≥n de activaci√≥n softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce377101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo (optimizer SGD, loss categorical_crossentropy, metrics accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo (batch_size=128, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo con los datos de test\n",
    "\n",
    "print(model.evaluate(x_train, y_train, batch_size=128))\n",
    "\n",
    "\n",
    "from matriz_confusion import graficar_matriz_de_confusion\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "y_ref = np.argmax(y_test,axis=1)\n",
    "etiquetas = ['0','1','2','3','4','5','6','7','8','9']\n",
    "graficar_matriz_de_confusion(y_ref, y_pred, etiquetas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
